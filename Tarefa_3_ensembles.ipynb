{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv(os.path.join('Dados', 'glass', 'glass.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = glass.iloc[:, 0:9]\n",
    "y = glass.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Nesse caso foi utilizada a entropia, pois o C4.5 usa esse critério. Isso foi feito pois o sklearn não implementa o C4.5, e sim o CART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'splitter':['random', 'best'], 'max_depth':[2, 3, 4, 5, 10, 20, 30, 60]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.64\n",
      "Melhores parâmetros: DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(dt, parameters, cv=10, scoring='f1_macro')\n",
    "model.fit(X, y)\n",
    "dt_base_estimator = model.best_estimator_\n",
    "print('F1-macro: %.2f' % model.best_score_)\n",
    "print('Melhores parâmetros: ' + str(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "- Bagging -> BaggingClassifier\n",
    "- Boosting -> AdaBoostClassifier\n",
    "- Random Forest -> RandomForestClassifier\n",
    "- XGBOOST -> XGBClassifier\n",
    "- Stacking -> StackingCVClassifier: Combinação de todos os ensembles testados e a decision tree.\n",
    "\n",
    "- Ambos bagging e boosting utilizaram como classificador base a decision tree criada anteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.68\n",
      "Melhores parâmetros: BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=20, n_jobs=None, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 20, 40, 80, 160, 320]}\n",
    "bagging = BaggingClassifier(random_state=42, base_estimator=dt_base_estimator)\n",
    "model = GridSearchCV(bagging, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "bagging_model = model.best_estimator_\n",
    "print('F1-macro: %.2f' % model.best_score_)\n",
    "print('Melhores parâmetros: ' + str(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.62\n",
      "Melhores parâmetros: AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'),\n",
      "          learning_rate=32.0, n_estimators=10, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 20, 40, 80, 160, 320, 640], 'learning_rate':[1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0]}\n",
    "boosting = AdaBoostClassifier(random_state=42, base_estimator=dt_base_estimator)\n",
    "model = GridSearchCV(boosting, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "boosting_model = model.best_estimator_\n",
    "print('F1-macro: %.2f' % model.best_score_)\n",
    "print('Melhores parâmetros: ' + str(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.72\n",
      "Melhores parâmetros: RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=20, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=None, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[10, 20, 40, 80, 160, 320, 640], \n",
    "              'max_depth':[10, 20, 40, 80, 160, 320, 640], \n",
    "              'min_samples_split':[2, 3, 4, 5, 6, 7, 8], \n",
    "              'min_samples_leaf':[1, 2, 3, 4], \n",
    "              'bootstrap':[True, False]}\n",
    "rf = RandomForestClassifier(criterion='entropy', random_state=42)\n",
    "model = GridSearchCV(rf, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "rf_model = model.best_estimator_\n",
    "print('F1-macro: %.2f' % model.best_score_)\n",
    "print('Melhores parâmetros: ' + str(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.67\n",
      "Melhores parâmetros: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, eval_metric='auc', gamma=0,\n",
      "       learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'booster':['gbtree', 'dart'], \n",
    "              'learning_rate':[0.1, 0.2, 0.3, 0.4], \n",
    "              'max_depth':[3, 6, 12, 24]}\n",
    "xgboost = XGBClassifier(seed=42, eval_metric='auc')\n",
    "model = GridSearchCV(xgboost, parameters, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "model.fit(X, y)\n",
    "xgboost_model = model.best_estimator_\n",
    "print('F1-macro: %.2f' % model.best_score_)\n",
    "print('Melhores parâmetros: ' + str(model.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro: 0.64 [Decision Tree]\n",
      "F1-macro: 0.68 [Bagging]\n",
      "F1-macro: 0.62 [AdaBoost]\n",
      "F1-macro: 0.72 [Random Forest]\n",
      "F1-macro: 0.67 [XGBOOST]\n",
      "F1-macro: 0.71 [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=4)\n",
    "sclf = StackingCVClassifier(classifiers=[dt_base_estimator, bagging_model, boosting_model, rf_model, xgboost_model], \n",
    "                            meta_classifier=lr, use_probas=True, random_state=42, use_features_in_secondary=False)\n",
    "\n",
    "for clf, label in zip([dt_base_estimator, bagging_model, boosting_model, rf_model, xgboost_model, sclf], \n",
    "                      ['Decision Tree', 'Bagging', 'AdaBoost', 'Random Forest', 'XGBOOST', 'StackingClassifier']):\n",
    "\n",
    "    scores = cross_val_score(clf, X.as_matrix(), y, cv=10, scoring='f1_macro')\n",
    "    print(\"F1-macro: %.2f [%s]\" % (scores.mean(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
